{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain langchain-community neo4j openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI = \"bolt://localhost:7687\"\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"gT83_w5bQ2@\"\n",
    "NEO4J_DATABASE = \"jobs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to GDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    database=NEO4J_DATABASE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher = \"\"\"\n",
    "  MATCH (n) \n",
    "  RETURN count(n)\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = kg.query(cypher)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[idx[\"name\"] for idx in kg.query(\"SHOW INDEXES\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = pl.read_parquet(\"job_data/jobs_2023_all_2024-02-23.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in jobs.sample(3).to_dicts():\n",
    "    print(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Jobs to GDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS_IN_GBD = 2000\n",
    "\n",
    "jobs_sample = jobs.sample(N_JOBS_IN_GBD)\n",
    "\n",
    "# list(jobs_sample.to_dicts()[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(jobs_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  'job_id',\n",
    "#  'job_title',\n",
    "#  'job_type',\n",
    "#  'job_specialization',\n",
    "#  'job_posted_at',\n",
    "#  'skills',\n",
    "#  'client_id',\n",
    "#  'client_name',\n",
    "#  'client_type',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobs_sample.to_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_job_node_query = \"\"\"\n",
    "MERGE(mergedJob:Job {job_id: $job_param.job_id})\n",
    "    ON CREATE SET \n",
    "        mergedJob.job_title = $job_param.job_title, \n",
    "        mergedJob.job_vertical = $job_param.job_type, \n",
    "        mergedJob.job_posted_at = $job_param.job_posted_at,\n",
    "        mergedJob.skills = $job_param.skills,\n",
    "        mergedJob.client_id = $job_param.client_id,\n",
    "        mergedJob.client_name = $job_param.client_name,\n",
    "        mergedJob.client_type = $job_param.client_type\n",
    "RETURN mergedJob\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(jobs_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(merge_job_node_query, \n",
    "         params={'job_param': jobs_sample.to_dicts()[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "CREATE CONSTRAINT unique_job IF NOT EXISTS \n",
    "    FOR (j:Job) REQUIRE j.job_id IS UNIQUE\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"SHOW INDEXES\")[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_count = 0\n",
    "for job in jobs_sample.to_dicts():\n",
    "    print(f\"Creating `:Job` node for job_id {job['job_id']}\")\n",
    "    kg.query(merge_job_node_query, \n",
    "            params={\n",
    "                'job_param': job,\n",
    "            })\n",
    "    job_count += 1\n",
    "print(f\"Created {job_count} job nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "         MATCH (j:Job)\n",
    "         RETURN count(j) as job_count\n",
    "         \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add chunks to GDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap  = 20,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,\n",
    "    separators = [\"\\n\\n\", \"\\n\", \". \", \"; \", \", \", \" \", \"\"],\n",
    "    keep_separator  = True,\n",
    ")\n",
    "\n",
    "# text_splitter.__dict__\n",
    "text_splitter._separators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_sample_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(jobs_sample.to_dicts()[job_sample_index][\"job_description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_chunks = text_splitter.split_text(jobs_sample.to_dicts()[job_sample_index][\"job_description\"])\n",
    "len(jd_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  'client_id',\n",
    "#  'client_name',\n",
    "#  'client_type',\n",
    "#  'job_id',\n",
    "#  'job_title',\n",
    "#  'job_description',\n",
    "#  'job_type',\n",
    "#  'job_specialization',\n",
    "#  'job_posted_at',\n",
    "#  'skills',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_job_description(job):\n",
    "    chunks_with_metadata = []\n",
    "    job_descr_chunks = text_splitter.split_text(job[\"job_description\"])\n",
    "    job_id = job[\"job_id\"]\n",
    "    \n",
    "    chunk_seq_id = 0\n",
    "    for chunk in job_descr_chunks:\n",
    "        chunks_with_metadata.append({\n",
    "            'jd_chunk_id': f'{job_id}-chunk{chunk_seq_id:04d}',\n",
    "            'job_id': job_id,\n",
    "            'jd_chunk_seq_id': chunk_seq_id,\n",
    "            'jd_chunk': chunk,\n",
    "        })\n",
    "        chunk_seq_id += 1\n",
    "    print(f'\\tSplit into {chunk_seq_id} chunks')\n",
    "    return chunks_with_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_chunks = split_job_description(jobs_sample.to_dicts()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_chunks[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_chunks[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_jd_chunk_node_query = \"\"\"\n",
    "MERGE(mergedChunk:JD_Chunk {jd_chunk_id: $chunkParam.jd_chunk_id})\n",
    "    ON CREATE SET \n",
    "        mergedChunk.job_id = $chunkParam.job_id, \n",
    "        mergedChunk.jd_chunk_seq_id = $chunkParam.jd_chunk_seq_id, \n",
    "        mergedChunk.jd_chunk = $chunkParam.jd_chunk\n",
    "RETURN mergedChunk\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(merge_jd_chunk_node_query, \n",
    "         params={'chunkParam': jd_chunks[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "CREATE CONSTRAINT unique_jd_chunk IF NOT EXISTS \n",
    "    FOR (c:JD_Chunk) REQUIRE c.jd_chunk_id IS UNIQUE\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"SHOW INDEXES\")[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_jd_chunks_to_gdb(jd_chunks, verbose=False):\n",
    "    node_count = 0\n",
    "    for chunk in jd_chunks:\n",
    "        if verbose:\n",
    "            print(f\"Creating `:JD_Chunk` node for JD chunk ID {chunk['jd_chunk_id']}\")\n",
    "        kg.query(merge_jd_chunk_node_query, \n",
    "                params={\n",
    "                    'chunkParam': chunk\n",
    "                })\n",
    "        node_count += 1\n",
    "    print(f\"Created JD chunk {node_count} nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_jd_chunks_to_gdb(jd_chunks, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "         MATCH (jdc:JD_Chunk)\n",
    "         RETURN count(jdc) as jd_chunks_count\n",
    "         \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(jobs_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_count = 0\n",
    "for job in jobs_sample.to_dicts():\n",
    "    print(f\"Creating `:JD_Chunk` nodes for job_id {job['job_id']}. Processed {job_count} jobs.\")\n",
    "    jd_chunks = split_job_description(job)\n",
    "    add_jd_chunks_to_gdb(jd_chunks)\n",
    "    job_count += 1\n",
    "print(f\"---------\\nCreated `:JD_Chunk` nodes for {job_count} jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "         MATCH (jdc:JD_Chunk)\n",
    "         RETURN count(jdc) as jd_chunks_count\n",
    "         \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'jd_chunk': 'Summary:',\n",
    "# 'job_id': 369533,\n",
    "# 'jd_chunk_id': '369533-chunk0000',\n",
    "# 'jd_chunk_seq_id': 0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher = \"\"\"\n",
    "  MATCH (of_same_job:JD_Chunk)\n",
    "    WHERE of_same_job.job_id = $job_id\n",
    "  RETURN of_same_job {.job_id, .jd_chunk_id, .jd_chunk_seq_id } as id_chunk_info\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "kg.query(cypher, params={\"job_id\": jobs_sample.to_dicts()[0][\"job_id\"]})[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher = \"\"\"\n",
    "  MATCH (of_same_job:JD_Chunk)\n",
    "    WHERE of_same_job.job_id = $job_id\n",
    "  RETURN of_same_job {.job_id, .jd_chunk_id, .jd_chunk_seq_id } as id_chunk_info \n",
    "    ORDER BY of_same_job.jd_chunk_seq_id ASC\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "kg.query(cypher, params={\"job_id\": jobs_sample.to_dicts()[0][\"job_id\"]})[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher = \"\"\"\n",
    "  MATCH (of_same_job:JD_Chunk)\n",
    "    WHERE of_same_job.job_id = $job_id\n",
    "  WITH of_same_job {.job_id, .jd_chunk_id, .jd_chunk_seq_id }\n",
    "    ORDER BY of_same_job.jd_chunk_seq_id ASC\n",
    "  RETURN collect(of_same_job)\n",
    "\"\"\"\n",
    "\n",
    "# kg.query(cypher, params={\"job_id\": jobs_sample.to_dicts()[0][\"job_id\"]})[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_linked_list_of_jd_chinks = \"\"\"\n",
    "  MATCH (of_same_job:JD_Chunk)\n",
    "    WHERE of_same_job.job_id = $job_id\n",
    "  WITH of_same_job\n",
    "    ORDER BY of_same_job.jd_chunk_seq_id ASC\n",
    "  WITH collect(of_same_job) as jd_chunk_list\n",
    "    CALL apoc.nodes.link(\n",
    "        jd_chunk_list, \n",
    "        \"NEXT\", \n",
    "        {avoidDuplicates: true}\n",
    "    )\n",
    "  RETURN size(jd_chunk_list)\n",
    "\"\"\"\n",
    "\n",
    "kg.query(cypher_linked_list_of_jd_chinks, params={\"job_id\": jobs_sample.to_dicts()[0][\"job_id\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.refresh_schema()\n",
    "print(kg.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_count = 0\n",
    "for job in jobs_sample.to_dicts():\n",
    "    print(f\"Creating a linked list of `:JD_Chunk` nodes for job_id {job['job_id']}\")\n",
    "    kg.query(cypher_linked_list_of_jd_chinks, params={\"job_id\": job[\"job_id\"]})\n",
    "    job_count += 1\n",
    "print(f\"---------\\nCreated linked list of `:JD_Chunk` nodes for {job_count} jobs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher = \"\"\"\n",
    "  MATCH (jdc:JD_Chunk), (j:Job)\n",
    "    WHERE jdc.job_id = j.job_id\n",
    "  MERGE (jdc)-[newRelationship:PART_OF]->(j)\n",
    "  RETURN count(newRelationship)\n",
    "\"\"\"\n",
    "\n",
    "kg.query(cypher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher = \"\"\"\n",
    "  MATCH (first:JD_Chunk), (j:Job)\n",
    "    WHERE first.job_id = j.job_id\n",
    "      AND first.jd_chunk_seq_id = 0\n",
    "  WITH first, j\n",
    "    MERGE (j)-[r:SECTION]->(first)\n",
    "  RETURN count(r)\n",
    "\"\"\"\n",
    "# TODO: rename: SECTION --> DESCRIPTION\n",
    "\n",
    "kg.query(cypher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher = \"\"\"\n",
    "  MATCH (j:Job)-[r:SECTION]->(first:JD_Chunk)\n",
    "    WHERE j.job_id = $job_id\n",
    "  RETURN first.jd_chunk_id, first.jd_chunk\n",
    "\"\"\"\n",
    "\n",
    "first_jd_chunk_info = kg.query(\n",
    "    cypher,\n",
    "    params = {\"job_id\": jobs_sample.to_dicts()[0][\"job_id\"]})\n",
    "\n",
    "first_jd_chunk_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher = \"\"\"\n",
    "  MATCH (first:JD_Chunk)-[:NEXT]->(nextChunk:JD_Chunk)\n",
    "    WHERE first.jd_chunk_id = $jd_chunk_id\n",
    "  RETURN nextChunk.jd_chunk_id, nextChunk.jd_chunk\n",
    "\"\"\"\n",
    "\n",
    "next_chunk_info = kg.query(\n",
    "    cypher,\n",
    "    params = {\"jd_chunk_id\": first_jd_chunk_info[0][\"first.jd_chunk_id\"]},\n",
    ")\n",
    "\n",
    "next_chunk_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher = \"\"\"\n",
    "    MATCH (c1:JD_Chunk)-[:NEXT]->(c2:JD_Chunk)-[:NEXT]->(c3:JD_Chunk) \n",
    "        WHERE c2.jd_chunk_id = $jd_chunk_id\n",
    "    RETURN c1.jd_chunk_id, c2.jd_chunk_id, c3.jd_chunk_id\n",
    "    \"\"\"\n",
    "\n",
    "kg.query(cypher,\n",
    "         params={\"jd_chunk_id\": next_chunk_info[0][\"nextChunk.jd_chunk_id\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher = \"\"\"\n",
    "    MATCH window = (c1:JD_Chunk)-[:NEXT]->(c2:JD_Chunk)-[:NEXT]->(c3:JD_Chunk) \n",
    "        WHERE c1.jd_chunk_id = $jd_chunk_id\n",
    "    RETURN length(window) as windowPathLength\n",
    "    \"\"\"\n",
    "\n",
    "kg.query(cypher,\n",
    "         params={\"jd_chunk_id\": next_chunk_info[0][\"nextChunk.jd_chunk_id\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_jd_chunk_info[0][\"first.jd_chunk_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher = \"\"\"\n",
    "  MATCH window=\n",
    "      (:JD_Chunk)-[:NEXT*0..1]->(c:JD_Chunk)-[:NEXT*0..1]->(:JD_Chunk) \n",
    "    WHERE c.jd_chunk_id = $jd_chunk_id\n",
    "  RETURN length(window)\n",
    "  \"\"\"\n",
    "\n",
    "kg.query(cypher,\n",
    "         params={\"jd_chunk_id\": first_jd_chunk_info[0][\"first.jd_chunk_id\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher = \"\"\"\n",
    "  MATCH window=\n",
    "      (:JD_Chunk)-[:NEXT*0..1]->(c:JD_Chunk)-[:NEXT*0..1]->(:JD_Chunk)\n",
    "    WHERE c.jd_chunk_id = $jd_chunk_id\n",
    "  WITH window as longestChunkWindow\n",
    "      ORDER BY length(window) DESC LIMIT 1\n",
    "  RETURN length(longestChunkWindow)\n",
    "  \"\"\"\n",
    "\n",
    "kg.query(cypher,\n",
    "         params={\"jd_chunk_id\": first_jd_chunk_info[0][\"first.jd_chunk_id\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create text vectors (embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kg.query(\"\"\"\n",
    "#          CREATE VECTOR INDEX `job_chunks` IF NOT EXISTS\n",
    "#           FOR (c:Chunk) ON (c.textEmbedding) \n",
    "#           OPTIONS { indexConfig: {\n",
    "#             `vector.dimensions`: 1536,\n",
    "#             `vector.similarity_function`: 'cosine'\n",
    "#          } }\n",
    "# \"\"\")\n",
    "\n",
    "# kg.query(\"\"\"\n",
    "#          CREATE VECTOR INDEX `job_chunks_test_3dim` IF NOT EXISTS\n",
    "#           FOR (c:Chunk) ON (c.textEmbedding_3dim) \n",
    "#           OPTIONS { indexConfig: {\n",
    "#             `vector.dimensions`: 3,\n",
    "#             `vector.similarity_function`: 'cosine'\n",
    "#          } }\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_indices = kg.query(\"SHOW INDEXES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kg.query(\"\"\"\n",
    "#     MATCH (chunk:Chunk) WHERE chunk.textEmbedding IS NULL\n",
    "#     WITH chunk, genai.vector.encode(\n",
    "#       chunk.text, \n",
    "#       \"OpenAI\", \n",
    "#       {\n",
    "#         token: $openAiApiKey, \n",
    "#         endpoint: $openAiEndpoint\n",
    "#       }) AS vector\n",
    "#     CALL db.create.setNodeVectorProperty(chunk, \"textEmbedding\", vector)\n",
    "#     \"\"\", \n",
    "#     params={\"openAiApiKey\":OPENAI_API_KEY, \"openAiEndpoint\": OPENAI_ENDPOINT} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kg.query(\"\"\"\n",
    "#     CALL apoc.ml.openai.embedding(['Text to create embedding'], $openAiApiKey) YIELD embedding\n",
    "#     \"\"\", \n",
    "#     params={\"openAiApiKey\":OPENAI_API_KEY})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kg.query(\"\"\"\n",
    "#     MATCH (chunk:Chunk) WHERE chunk.textEmbedding IS NULL\n",
    "#     WITH\n",
    "#         chunk,\n",
    "#         CALL apoc.ml.openai.embedding([chunk.text], $openAiApiKey) YIELD embedding AS vector\n",
    "#     CALL db.create.setNodeVectorProperty(chunk, \"textEmbedding\", vector)\n",
    "#     \"\"\", \n",
    "#     params={\"openAiApiKey\":OPENAI_API_KEY, \"openAiEndpoint\": OPENAI_ENDPOINT} )\n",
    "\n",
    "# # CALL apoc.ml.openai.embedding(['Knowledge Graphs work well with LLMs'], $apiKey, {}) yield index, text, embedding;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kg.query(\"\"\"\n",
    "#     MATCH (chunk:Chunk) WHERE chunk.textEmbedding_3dim IS NULL\n",
    "#     WITH\n",
    "#         chunk,\n",
    "#         [0.1, 0.2, 0.3] AS vector\n",
    "#     CALL db.create.setNodeVectorProperty(chunk, \"textEmbedding_3dim\", vector)\n",
    "#     \"\"\", \n",
    "#     params={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = kg.query(\"\"\"\n",
    "#     MATCH (chunk:Chunk) \n",
    "#     WHERE chunk.textEmbedding_3dim IS NOT NULL\n",
    "#     RETURN chunk.job_descr_chunk, chunk.textEmbedding_3dim\n",
    "#     LIMIT 20\n",
    "#     \"\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SEARCH\n",
    "\n",
    "# kg.query(\"\"\"\n",
    "#     CALL db.index.vector.queryNodes(\n",
    "#         $index_name, \n",
    "#         $top_k,\n",
    "#         $question_embedding\n",
    "#         ) YIELD node AS chunk, score\n",
    "#     RETURN chunk.job_id, chunk.job_descr_chunk, score\n",
    "#     \"\"\", \n",
    "#     params={\"index_name\": \"job_chunks_test_3dim\",\n",
    "#             \"top_k\": 5,\n",
    "#             \"question_embedding\": [0.099, 0.21, 0.29],\n",
    "#             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(\n",
    "    model = \"text-embedding-3-small\",\n",
    "    # openai_api_key = OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = embeddings.embed_query(\"Text to vectorize\")\n",
    "len(emb), emb[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai_client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(\n",
    "#     openai_client.embeddings.create(\n",
    "#         input=[result[0][\"chunk.job_descr_chunk\"]],\n",
    "#         model=\"text-embedding-3-small\",\n",
    "#     ).data[0].embedding\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genete embeddings (create index if not exist)\n",
    "\n",
    "Neo4jVector.from_existing_graph(\n",
    "    OpenAIEmbeddings(\n",
    "        model = \"text-embedding-3-small\",    \n",
    "    ),\n",
    "    url = NEO4J_URI,\n",
    "    username = NEO4J_USERNAME,\n",
    "    password = NEO4J_PASSWORD,\n",
    "    database=NEO4J_DATABASE,\n",
    "    index_name = \"vector_jd_chunk\",\n",
    "    node_label=\"JD_Chunk\",\n",
    "    text_node_properties=[\"jd_chunk\"],\n",
    "    embedding_node_property='jd_chunk_embedding',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_indices = kg.query(\"SHOW INDEXES\")\n",
    "\n",
    "[index[\"name\"] for index in db_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.refresh_schema()\n",
    "print(kg.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = kg.query(\"\"\"\n",
    "    MATCH (chunk:JD_Chunk) \n",
    "    WHERE chunk.jd_chunk_embedding IS NOT NULL\n",
    "    RETURN chunk.jd_chunk, chunk.jd_chunk_embedding\n",
    "    LIMIT 3\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result[0][\"chunk.jd_chunk_embedding\"]), result[0][\"chunk.jd_chunk_embedding\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genete embeddings (create index if not exist)\n",
    "\n",
    "Neo4jVector.from_existing_graph(\n",
    "    OpenAIEmbeddings(\n",
    "        model = \"text-embedding-3-small\",    \n",
    "    ),\n",
    "    url = NEO4J_URI,\n",
    "    username = NEO4J_USERNAME,\n",
    "    password = NEO4J_PASSWORD,\n",
    "    database=NEO4J_DATABASE,\n",
    "    index_name = \"vector_job_title\",\n",
    "    node_label=\"Job\",\n",
    "    text_node_properties=[\"job_title\"],\n",
    "    embedding_node_property=\"job_title_embedding\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_indices = kg.query(\"SHOW INDEXES\")\n",
    "\n",
    "[index[\"name\"] for index in db_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.refresh_schema()\n",
    "print(kg.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = kg.query(\"\"\"\n",
    "    MATCH (j:Job) \n",
    "    WHERE j.job_title_embedding IS NOT NULL\n",
    "    RETURN j.job_title, j.job_title_embedding\n",
    "    LIMIT 3\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0][\"j.job_title\"], len(result[0][\"j.job_title_embedding\"]), result[0][\"j.job_title_embedding\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full text index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.refresh_schema()\n",
    "print(kg.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "CREATE FULLTEXT INDEX fulltext_job_title\n",
    "  IF NOT EXISTS\n",
    "  FOR (job:Job) \n",
    "  ON EACH [job.job_title]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "CREATE FULLTEXT INDEX fulltext_skills\n",
    "  IF NOT EXISTS\n",
    "  FOR (job:Job) \n",
    "  ON EACH [job.skills]\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector/semantic retrieval from GDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_vector_store = Neo4jVector.from_existing_graph(\n",
    "    OpenAIEmbeddings(\n",
    "        model = \"text-embedding-3-small\",\n",
    "        # openai_api_key = OPENAI_API_KEY,    \n",
    "    ),\n",
    "    url = NEO4J_URI,\n",
    "    username = NEO4J_USERNAME,\n",
    "    password = NEO4J_PASSWORD,\n",
    "    database=NEO4J_DATABASE,\n",
    "    index_name = \"job_chunks\",\n",
    "    node_label=\"Chunk\",\n",
    "    text_node_properties=[\"job_descr_chunk\"],\n",
    "    embedding_node_property='textEmbedding',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = neo4j_vector_store.as_retriever()  # k=4 <-- default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "#     ChatOpenAI(\n",
    "#         temperature=0,\n",
    "#         openai_api_key=OPENAI_API_KEY,\n",
    "#     ), \n",
    "#     chain_type=\"stuff\", \n",
    "#     retriever=retriever\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain(\n",
    "#     {\"question\": \"automation of the processes\"},\n",
    "#     return_only_outputs=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_result = retriever.invoke(\"automation of the processes\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_result[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatOpenAI(\n",
    "#     model=\"gpt-3.5-turbo-0125\",\n",
    "#     temperature=0,\n",
    "#     openai_api_key=OPENAI_API_KEY,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = GraphCypherQAChain.from_llm(\n",
    "#     ChatOpenAI(\n",
    "#         model=\"gpt-3.5-turbo-0125\",\n",
    "#         temperature=0,\n",
    "#         # openai_api_key=OPENAI_API_KEY,\n",
    "#     ),\n",
    "#     graph=kg,\n",
    "#     verbose=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain.run(\"\"\"\n",
    "# automation of the processes\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        temperature=0,\n",
    "        # openai_api_key=OPENAI_API_KEY,\n",
    "    )\n",
    "\n",
    "system_prompt = (\n",
    "    \"Use the given context to answer the question. \"\n",
    "    \"If you don't know the answer, say you don't know. \"\n",
    "    \"Use three sentence maximum and keep the answer concise. \"\n",
    "    \"Context: {context}\"\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"input\": \"automation of the processes\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"input\": \"What are the main skills?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
